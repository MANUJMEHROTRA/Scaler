{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lecture Notes for session conducted on September 02, 2022\n",
        "\n",
        "https://www.scaler.com/academy/mentee-dashboard/class/34686/session\n",
        "\n",
        "**Content**\n",
        "\n",
        "1.   Quick Recap.\n",
        "2.   Chain Rule.\n",
        "3.   Memoization.\n",
        "4.   Back Propogation.\n",
        "5.   Various Activation Functions."
      ],
      "metadata": {
        "id": "TJZ-3vAUjCBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Overview"
      ],
      "metadata": {
        "id": "moKOTmRDw8x6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Every Deep Learning model at their very core have Back Propogation.\n",
        "- We will build understanding of how they work.\n",
        "- Hinton and others had proposed with working on Back Propogation in 1980's.\n",
        "- It's widely used in Computer Vision (CV), Natural Language Processing (NLP), Speech processing and many other DL applications.\n",
        "  <img src='https://drive.google.com/uc?id=1HrYRRZE03uwG6anEuX-KjzWgs9KCp4ZG'>"
      ],
      "metadata": {
        "id": "oA8XruAdn_OS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Quick Recap:"
      ],
      "metadata": {
        "id": "_P-0d3sm3f6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- MLP consists of multiple function compositions.\n",
        "- Activation functions have to be non-linear.\n",
        "- Logistic Regression and Linear SVM can be represented as Single Neuron Model.\n",
        "- We saw a Brute Force Approach to compute $\\frac{\\partial Loss}{\\partial w^k_{ij}}$ $\\forall$ $weights^k_{ij}$ using Gradient Descent.\n",
        "  <img src='https://drive.google.com/uc?id=1Bz6YoRkmUNkMpfYyUEpP-cthgbrzFv85'>\n"
      ],
      "metadata": {
        "id": "B_p7CcYdqs4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Miscellaneous Questions:"
      ],
      "metadata": {
        "id": "Zz2j3HxPcgzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** When forward propagation is used, is it possible to have more activation functions at layer 2 than at layer 1?\n",
        "\n",
        "***Answer:***\n",
        "- Yes it is possible. For e.g. a Fully connected layer as shown below.\n",
        "- Basically, number of neurons in each layer and number of layers are treated as hyper parammeters.\n",
        "  <img src='https://drive.google.com/uc?id=1RpEo93Dlzn3ss6S7dUodJNL2llue_a5Q'>\n",
        "- But there is a caveat to this. Imagine we have a d-dimensional input $x_i\\in \\mathbb{R}^d$ where $d = 100$ for a binary class classification problem.\n",
        "  <img src='https://drive.google.com/uc?id=1OuA_cfR_l-TiZ5wJZya53ZQtbwq_TjvC'>\n",
        "- We have 3 layers $L_1, L_2, L_3$ each of them fully connected with output layer for a binary classification problem. So, to move from d-dimensional input to 1-dimensional output, we need to have reducing number of neurons in each layer.\n",
        "- In the above example, $L_1 \\to $ 20 neurons, $L_2 \\to $ 10 neurons and $L_3 \\to $ 3 neurons.\n",
        "- There are exceptions to this as well. For e.g. U-Net that will be covered in Computer Vision (CV) section.\n"
      ],
      "metadata": {
        "id": "PiE-txspqVWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Can you consider a real-world business analogy to explain multi-layer Perceptrons?\n",
        "\n",
        "***Answer:***\n",
        "- From practical standpoint, MLP are only comparable to GBDT. On Tabular data, GBDT models are not beatable by DL models as the performance is very similar.\n",
        "- But for Image/Text/Speech there are specialized DL architectures which are very superior.\n",
        "- So for any real world scenario seen for classification and regression until now (previous classes),  we can use MLP. MLPs create a very good non-linear model.\n",
        "\n"
      ],
      "metadata": {
        "id": "4Ey9rk-x09SS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Can we use different activation functions at different layers.\n",
        "\n",
        "***Answer:***\n",
        "- Theoretically we can. But research shows that having different activation functions does not change performance much.\n",
        "- Hence for coding simplicity we go for same activation function.\n",
        "  <img src='https://drive.google.com/uc?id=19VeufnPRhi9Z7ObSSNOeCU_10hA6CL_H'>\n"
      ],
      "metadata": {
        "id": "VblV62L8qbyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Why should all activation functions be non-linear.\n",
        "\n",
        "***Answer:***\n",
        "- If we don't have non-linear activation function, then the output would be linear itself.\n",
        "  <img src='https://drive.google.com/uc?id=1WTy3VRkPAG4xs702s4_BuZe4t23ZOJUd'>\n",
        "- Since we use function compositions, only non-linear functions will produce non-linear output.  \n",
        "  <img src='https://drive.google.com/uc?id=11FBtco7-9zLw2gdNOnxtgQz_E00N4PBG'>\n",
        "\n"
      ],
      "metadata": {
        "id": "ukGV2GAOq5H8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** If we use mix of linear + non-linear activation, the layers with linear function would be useless, is that right?\n",
        "\n",
        "***Answer:***\n",
        "- Yes, having linear terms makes it useless.\n"
      ],
      "metadata": {
        "id": "LQvpunSA2zkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Back Propogation: Task\n"
      ],
      "metadata": {
        "id": "zMgZkS2Jq_IF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Imagine we have 4 dimensional dataset $x_i \\in \\mathbb{R}^4$ and have Fully connected network as shown below.\n",
        "  <img src='https://drive.google.com/uc?id=1ONdrj4M5dl4jZpfw_bVeEXg5WfR3Aphm'>\n",
        "- First layer has 3 neurons $f_{11}, f_{12}, f_{13}$, second layer has 2 neurons $f_{21}, f_{22}$ and final layer has 1 neuron $f_{31}$.\n",
        "- Assume that it is a binary classification problem.\n",
        "- So for a given Dataset $D = \\bigg\\{ (x_i, y_i) \\bigg\\}_{i=1}^{n}$, task is to determine $ W^{1}_{4*3}, \\ b^{1}_{3*1}, \\ \\  W^{2}_{3*2}, b^{2}_{2*1}  \\ \\ W^{3}_{2*1}, b^{3}_{1*1}$\n",
        "- These are the parameters we want to estimate.\n",
        "\n"
      ],
      "metadata": {
        "id": "x1ViAftN6Z_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Quick Recap of Brute Force Approach in MLP:"
      ],
      "metadata": {
        "id": "0PV9tk-X8XPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Initialize all parameters randomly. As a Pre-processing step, we need to standardize data.\n",
        "2.  $\\forall x_i's$, we compute $\\hat{y_i}$ using Forward Propogation in MLP.\n",
        "3.  We compute loss functionfor all $i's$ as $\\sum_{i=1}^{n} \\ Loss(y_i, \\hat{y_i})$ where $MSE \\to$ Linear Regression and $Log-Loss \\to$ Classification.\n",
        "4.  $W^k_{ij}$ and $b^k_{ij}$ are updated as:\n",
        "$${W^k_{ij}}_{new} = {W^k_{ij}}_{old} - \\eta * \\frac{\\partial Loss}{\\partial W^k_{ij}}\\biggr\\vert_{{W^k_{ij}}_{old}}$$\n",
        "$${b^k_{ij}}_{new} = {b^k_{ij}}_{old} - \\eta * \\frac{\\partial Loss}{\\partial b^k_{ij}}\\biggr\\vert_{{b^k_{ij}}_{old}}$$\n",
        "5.  Repeat steps $2,3,4$ until convergence.\n",
        "\n",
        "*Note:*  \n",
        "- Here $\\eta$ is learning rate.\n",
        "- Convergence means until ${w^k_{ij}}_{new}$ is very similar to ${w^k_{ij}}_{old}$ and ${b^k_{ij}}_{new}$ is very similar to ${b^k_{ij}}_{old}$.\n"
      ],
      "metadata": {
        "id": "3V4P6bpS8dcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Updation of weights:"
      ],
      "metadata": {
        "id": "5sZJmu0h_Bw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Computing the partial derivatives is complex.\n",
        "  <img src='https://drive.google.com/uc?id=1FO8cxsp8Y7f40xepCG8akVTAomxPSbzF'>\n",
        "- Imagine we want to update $w^1_{11}$ as it impacts loss. But there are so many other functions we have to account for. So we have to compute it efficiently."
      ],
      "metadata": {
        "id": "Y2sKsd-e-34p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** For simplicity, here we assume we pass input sequencely. Right?\n",
        "\n",
        "***Answer:***\n",
        "- No, we can also pass it in a single go. Imagine we have 4-dimensional input dataset $X_{n*d}$ and we have weight matrix $W^1_{4*3}$. We can do a simple matrix multiplication.\n",
        "- We saw in last class that in Gradient Descent we compute $\\frac{\\partial L}{\\partial W^K_{ij}}$ using all $n$ points.\n",
        "- Whereas in Stochastic Gradient Descent we compute $\\frac{\\partial L}{\\partial W^K_{ij}}$ using one random point.\n",
        "- Batch-Gradient Descent, we compute $\\frac{\\partial L}{\\partial W^K_{ij}}$ using $m$ random points.\n",
        "  <img src='https://drive.google.com/uc?id=1sN2rMnx8jhjjWl6fD7A0smfR2it8wpRy'>\n",
        "- Ideally, to compute $Loss$ we need to take all $n$ points and loss is computed as:\n",
        "$$Loss = \\sum_{i=1}^{n}L(y_i,\\hat{y})$$\n",
        "- But if we use $m$ points then it is Batch-Gradient Descent. Also computation is faster.\n",
        "\n",
        "Note: We use Batch-Gradient Descent in most DL problems.\n",
        "\n"
      ],
      "metadata": {
        "id": "uYHTC9-U78kX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Challenge"
      ],
      "metadata": {
        "id": "WN8JwgLfAWY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The challenge is to compute $\\frac{\\partial L}{\\partial W^k_{ij}}$.\n",
        "- So $\\frac{\\partial L}{\\partial W^k_{ij}}$ is computed backwards using chain rule.\n",
        "- It is computed from Loss till the first layer.\n",
        "  <img src='https://drive.google.com/uc?id=1kJeDOEzqm0pAfnYKWpqec4GQOQesPeOW'>"
      ],
      "metadata": {
        "id": "mfu_g3rpAWnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Chain rule suggests that, $\\frac{\\partial L}{\\partial O_{31}}$ depends on $w^3_{31}$ and $w^3_{21}$.\n",
        "- Similarly, output $O_{21}$ depends on $w^2_{11}$, $w^2_{21}$ and $w^2_{31}$ and so on.\n",
        "- To compute $\\frac{\\partial L}{\\partial w^1_{11}}$, we want to find all those components that impact it.\n",
        "  <img src='https://drive.google.com/uc?id=1TCSz3jYrYZkLBE6ywxWlctbLvnWp8Ato'>\n",
        "- Figure above denotes the partial derivatives that need to be computed using chain rule.\n",
        "- For simplicity, we will consider only one path."
      ],
      "metadata": {
        "id": "UauDXVfUANZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- First, we compute $\\frac{\\partial L}{\\partial O_{31}}$ as we need it to compute $w^3_{11}$ and $w^3_{21}$\n",
        "- Similarly, we compute $\\frac{\\partial L}{\\partial O_{21}}$ as we need it to compute $w^2_{11}$, $w^2_{21}$ and $w^2_{31}$ and so on.\n",
        "  <img src='https://drive.google.com/uc?id=1RiKQSwcHnIWW5g80WtXgfBqleQGdMbaa'>\n",
        "- These partial derivates are computed and stored in memory as they would be needed multiple times.\n"
      ],
      "metadata": {
        "id": "6MjnZkvILz6p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Can we say that forward prop is output computation step and then backwards prop is optimization step. Same as classical ML or any other GD based optimization.\n",
        "\n",
        "***Answer:*** Yes, that is correct."
      ],
      "metadata": {
        "id": "71dbXJOCDQAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** In Classical ML we don't have back propogation. Right?\n",
        "\n",
        "***Answer:***\n",
        "- In classical ML we didn't require back propogation. For e.g. in Logistic Regression we just have one neuron, partial derivative is still computed.\n",
        "- But we didn't have many layers. Just single neuron and single layer.\n",
        "  <img src='https://drive.google.com/uc?id=1fpBdwQeHmUuuPhVz8Yk87b50Eptt4ayN'>"
      ],
      "metadata": {
        "id": "rFoa4qPfDlwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** In simpler terms can we say: after each forward pass through a network, backpropagation performs a backward pass while adjusting the model’s parameters (weights and biases) so that the loss function is minimized?\n",
        "\n",
        "***Answer:***\n",
        "- Yes, that is correct. Let's take a simple path to understand it better.\n",
        "- Loss is computed as:\n",
        "\\begin{equation}\n",
        "  \\begin{aligned}\n",
        "    Loss & = L(y,f_3(o_1,o_2))\\\\\n",
        "      & = L(y,f_3(f_1(w),f_2(w)))\n",
        "  \\end{aligned}\n",
        "\\end{equation}\n",
        "  <img src='https://drive.google.com/uc?id=1_7j58vna-_wJfLGG3Z6QRQEXBctnDIkE'>\n"
      ],
      "metadata": {
        "id": "qWOuwvGPEULc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** When we are computing chain rule, do we take derivative wrt output of a particular node or weight?\n",
        "\n",
        "***Answer:***\n",
        "- Yes, derivative is wrt to outputs in order to update weights."
      ],
      "metadata": {
        "id": "T_7GJyOMHqMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Core Ideas in Back Propogation:"
      ],
      "metadata": {
        "id": "iia1JsYII_Y_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Back propogation uses chain-rule to compute partial derivative of Loss wrt $w^k_{ij}$.\n",
        "- It uses memoization to store computational results as they are used over and over again. Memoization is a concept used in Dynamic Programming.\n",
        "  <img src='https://drive.google.com/uc?id=1n83efhiYNPucuUFkUOUCKKiCh99tqIX8'>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lwkFhPROsdc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** But computation of derivatives wrt to outputs will differ for different weights right ? so can we reuse this?\n",
        "\n",
        "***Answer:***\n",
        "- Imagine we have activation function $f_{31}$ that computes output $O_{31}$. This is passed to the Loss function $Loss(y_i,\\hat{y})$. Let say loss function is MSE for Regression Problem.\n",
        "- So $\\frac{\\partial L}{\\partial O_{31}}$ is computed as:\n",
        "\\begin{equation}\n",
        "  \\begin{aligned}\n",
        "    \\frac{\\partial L}{\\partial O_{31}} & = \\frac{\\partial }{\\partial O_{31}} \\ (y_i - O_{31})^2\\\\\n",
        "      & = -2(y_i - O_{31})\\\\\n",
        "  \\end{aligned}\n",
        "\\end{equation}\n",
        "\n",
        " <img src='https://drive.google.com/uc?id=1NvbDBUN29n1obnnK5GafIwaUQ1PT9GAQ'>\n",
        "- Notice, that in order to compute $w^1_{11}$ and $w^1_{21}$ we need derivative $\\frac{\\partial L}{\\partial O_{11}}$.\n",
        "  <img src='https://drive.google.com/uc?id=1U5MJ5eZxxUxiqAsiWO_rPSN1okD3sn0i'>\n",
        "- So here we need this derivative twice."
      ],
      "metadata": {
        "id": "SASpHkqiMma-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Although we could have used $w$ in chain rule intermediate derivatives, using $O$ eases the computation? (as $O$ are anyway dependent on prev layer $w's$), is the understanding right?\n",
        "\n",
        "***Answer:*** Yes, using $O$ eases computation."
      ],
      "metadata": {
        "id": "tQMojrxTPhff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Wouldn't  all other $w's$ be taken as constant while we are computing derivative wrt one particular $w$? Therefore we use outputs instead of other $w's$.\n",
        "\n",
        "***Answer:***\n",
        "- Yes, we will look at all other weights as constant.\n",
        "  <img src='https://drive.google.com/uc?id=1IrdHOo_WObmiCQ_y3Grrx6HH8j58vgM5'>\n",
        "- Imagine, we have a function $(f) = w_1x_1 + w_2x_2$.\n",
        "- So $\\frac{\\partial O}{\\partial w_1} = x_1$ and $\\frac{\\partial O}{\\partial w_2} = x_2$.\n"
      ],
      "metadata": {
        "id": "G5ImYBFnPrKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Once the weight changes, the value of the store derivative (output) will change. so we need to store again?\n",
        "\n",
        "***Answer:***\n",
        "- Let $x_i$ be input that is used to predict output $O_i$ by passing through a MLP which has many weights.\n",
        "- On predicted output, we compute loss.\n",
        "- In back propogation, we update all weights. In the next iteration these updated weights are used to predict the output after which loss is computed and we do back propogation again until convergence.\n",
        "  <img src='https://drive.google.com/uc?id=1NRJNN_533-wevZGXpxgnft7msNa5yrmt'>"
      ],
      "metadata": {
        "id": "T8w7pfTGQdG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Can we control the number of iterations if we have a higher threshold for error?\n",
        "\n",
        "***Answer:***\n",
        "- In MLP, we continue iterations till convergence or change in loss is very small."
      ],
      "metadata": {
        "id": "7gehzPUqRfpc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:***  In each forward pass, we will generally be passing a minibatch, right? Is it recommended to pass only one data element at a time or all of them at once?\n",
        "\n",
        "***Answer:***\n",
        "- Imagine we have 100 million datapoints for a 1000-dimensional features.\n",
        "- In such cases, it makes sense to use batch-GD.\n",
        "<img src='https://drive.google.com/uc?id=1sN2rMnx8jhjjWl6fD7A0smfR2it8wpRy'>"
      ],
      "metadata": {
        "id": "4LwgXnJkR8vt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Space complexity also matters?\n",
        "\n",
        "***Answer:***\n",
        "- Yes. Sometimes, training takes weeks even with powerful GPUs and this is very common."
      ],
      "metadata": {
        "id": "H0DxK0n7SpG8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Back Propogation: Quick Recap"
      ],
      "metadata": {
        "id": "X6RlRBofS4vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Given a Dataset $\\bigg\\{ (x_i,y_i) \\bigg\\}_{i=1}^{n}$, task is to compute $w^k_{ij}$ and $b^k_{ij}$:\n",
        "  <img src='https://drive.google.com/uc?id=1MAYVrCN2IKCa5zx7jHlKCmEWBXlsRye5'>\n",
        "1. Initialize $w^k_{ij}$ randomly and $\\eta \\to$ learning rate.\n",
        "  <img src='https://drive.google.com/uc?id=1_0w8AztHucE7ZViBn-pMDceNh7XZWXy_'>\n",
        "2. Compute Forward propogation using batch gradient descent.\n",
        "3. Compute Loss.\n",
        "4. Update weights backwards i.e. from output to input. Keep the computed partial derivatives in memory for reuse. Compute them using chain-rule.\n",
        "  <img src='https://drive.google.com/uc?id=1PJTNZFxZA1wp5Ykn8UtFSzsVnKOEHHS4'>\n",
        "5. Repeat steps $2,3,4$ until convergence.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wU0ZsshZstOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Key points for Back Propogation:"
      ],
      "metadata": {
        "id": "rB_A-on-Ue6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Activation function and loss function should be differentiable.\n",
        "<img src='https://drive.google.com/uc?id=1kShQ85Ls-BZ2vZdPhbymE_W-LMXbhfMN'>\n",
        "- Simple back propogation is slow. (Later we will look into how to speed this up).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sTJhP0Z5s_XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Does it happen that a very computationally complex model is in training and we get an error (let's say) on $7^{th}$ day of training; the training failed because of a very silly issue like matrix multiplication on incompatible dimensions.\n",
        "\n",
        "***Answer:***\n",
        "- That doesn't happen much as we can do 1 FP and 1 BP to check if all the dimensions are correctly aligned.\n",
        "- Then we can do one more iteration of 1 FP and 1 BP and compute the loss. If loss decreases in comparison with previous iteration, then we can run more iterations.\n",
        "\n",
        "<img src='https://drive.google.com/uc?id=1nnbH1u7sUUPXmsLT2NpS5aHCYjmjSvxZ'>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ybQImtiytFqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Mini batch - Random Sample k points are picked randomly at every iteration?\n",
        "\n",
        "***Answer:*** Yes that is right. Mini-batch GD is stochastic in nature."
      ],
      "metadata": {
        "id": "SkG3DPJYVr8R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Question:*** Since these are long running models. If a step fails, can we resume it from that step ? or should we start all over again ?\n",
        "\n",
        "***Answer:***\n",
        "- Imagine we did 100 iterations. Then we store the weights on the disk.\n",
        "- It might happen that further processing gets interrupted due to power cut or system crashing due to overheating problem.\n",
        "- We can resume with stored weights and need not start from scratch.\n",
        "  <img src='https://drive.google.com/uc?id=1Xr45HhfJoNM6neSZlnzc5ITgDImYKdhk'>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ujyvbDlqtQm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Activation Functions:"
      ],
      "metadata": {
        "id": "doTolm12Wb4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Sigmoid:"
      ],
      "metadata": {
        "id": "0jiDyE46Wgl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- An important requirement for any activation functions is that it should be a non-linear function.\n",
        "  <img src='https://drive.google.com/uc?id=1M06K557EfmmUkEZY4oWWAYtpA_yurGcs'>\n",
        "- Sigmoid activation function was very popular in 1980's and 1990's and represented as:\n",
        "$$\\sigma(Ƶ) = \\frac{1}{1+e^{-Ƶ}} = \\frac{e^{Ƶ}}{1+e^{Ƶ}} \\ where \\ Ƶ = w^Tx+b$$\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J4tu-9OQtV_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It was very popular as derivative is always positive.\n",
        "- It's derivative is $\\sigma'(Ƶ) = \\frac{\\partial \\sigma}{\\partial Ƶ} = \\sigma(Ƶ)*(1 - \\sigma(Ƶ))$.\n",
        "- Value of the derivative lies between 0 and 1. Infact it is less than 0.3.\n",
        "  <img src='https://drive.google.com/uc?id=1YsuzkFwJUxGkAtjV8_QYnui4Sx_kqurC'>\n",
        "\n"
      ],
      "metadata": {
        "id": "KgDktJ_ptif-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Tanh:"
      ],
      "metadata": {
        "id": "uNdzM_RNFiQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tanh activation function is represented as:\n",
        "$$\\tanh(Ƶ) = \\frac{e^{Ƶ} - e^{-Ƶ}}{e^{Ƶ} + e^{-Ƶ}} \\ where \\ Ƶ = w^Tx+b$$\n",
        "- It's derivative is $\\tanh'(Ƶ) = 1 - tanh^2(Ƶ)$.\n",
        "  <img src='https://drive.google.com/uc?id=10beKL1EA15lmWHQV_r9--QFAUscr_hxQ'>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6Pxw1swTtnfV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Derivative of Tanh lies between $0 < tanh'(Ƶ) \\le 1$.\n",
        "<img src='https://drive.google.com/uc?id=15DUUHdBJU0Ss-baTcAU5pFXzUoinhp4s'>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ociqnv4it35V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Limitations of Sigmoid and Tanh:"
      ],
      "metadata": {
        "id": "4zjGtbLsIJ4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Imagine all the activation functions are Sigmoid/Tanh. Then the derivative will be between 0 and 1.\n",
        "- Let say we have 50 layers, then there is a risk.\n",
        "  <img src='https://drive.google.com/uc?id=1HXmRTHU683Dvkjg5eWeARhu5ORvbKMwI'>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EjvOshO9uHMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If we multiply lots of values which are between 0 and 1, then it becomes miniscule.\n",
        "- This problem is also known as vanishing gradients.\n",
        "  <img src='https://drive.google.com/uc?id=1F2VKIgOSyfEeO0g8gq7uuZ9fq5Q_kktK'>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8ot-9g3ZuMnv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Rectified Linear Unit (ReLu):"
      ],
      "metadata": {
        "id": "vVxUMFdXJKL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The problem of vanishing gradients was overcome with introduction of Rectified Linear Unit (ReLu).\n",
        "- ReLu is represented as $ReLu(Ƶ) = max(0,Ƶ)$.\n",
        "- It's derivative is defined as:\n",
        "\\begin{equation}\n",
        "  ReLu(Ƶ) =\n",
        "    \\begin{cases}\n",
        "      1 & \\text{if Ƶ > 0}\\\\\n",
        "      0 & \\text{if Ƶ ≤ 0}\n",
        "    \\end{cases}       \n",
        "\\end{equation}  \n",
        "- This is simple and fast.\n",
        "  <img src='https://drive.google.com/uc?id=1P7WY3LQ0cUlGCRdRob00MHKYMLW80He7'>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gnTWKROUuWTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ReLu is most widely used. Its derivative is either $0$ or $1$.\n",
        "- So there is no problem of vanishing gradients.\n",
        "  <img src='https://drive.google.com/uc?id=1t7Utm0KjyJXX0xccsTiPJELd7SPc4f_W'>\n",
        "- But there is a problem when its value is 0. Then entire value of partial differentiation becomes 0 if a single value is $0$.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IDNdvlVuufiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Leaky ReLu:"
      ],
      "metadata": {
        "id": "eOxOO68UK3xO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ReLu activation function has a problem when its value is $0$. Then entire value of partial differentiation becomes 0 if a single value is $0$.\n",
        "- To overcome this, we have a small gradient $\\alpha$ on the negative side instead of flat line.\n",
        "  <img src='https://drive.google.com/uc?id=1hmyLlbt2NF8gmRMfUICRdnEC9vlPBCbO'>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tfWrMLSQukgT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Next Class overview:"
      ],
      "metadata": {
        "id": "70ojVvKCL239"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Softmax and Cross Entropy.\n",
        "- Back propogation code.\n",
        "  <img src='https://drive.google.com/uc?id=148m7nk4Rg6hUe5B6XcJCXH4xe2at1dei'>\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GuJ254MuupRa"
      }
    }
  ]
}